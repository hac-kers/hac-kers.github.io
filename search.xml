<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>图像分类(VGG)(1)</title>
      <link href="/2023/10/14/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB-VGG-1/"/>
      <url>/2023/10/14/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB-VGG-1/</url>
      
        <content type="html"><![CDATA[<h1 id="已完成训练的VGG模型的使用方法"><a href="#已完成训练的VGG模型的使用方法" class="headerlink" title="已完成训练的VGG模型的使用方法"></a>已完成训练的VGG模型的使用方法</h1><p>使用ImageNet数据集中已经提前训练好网络参数的VGG-16模型来实现对未知图片进行自动分类处理的程序。<br>ImageNet是斯坦福大学从互联网上收集的已分类的图像数据集，ILSVRC竞赛常用（ImageNet Large Scale Visual Recognition Challenge）<br>Torch中可以轻松使用ImageNet数据集中的ILSVRC2012数据集（分类数：1000种；训练用数据：120万张；验证用数据：5万张；测试用数据：10万张）</p><h2 id="文件夹准备"><a href="#文件夹准备" class="headerlink" title="文件夹准备"></a>文件夹准备</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> urllib<span class="token punctuation">.</span>request<span class="token keyword">import</span> zipfile<span class="token comment">#·文件夹“data”不存在时制作</span>data_dir <span class="token operator">=</span> <span class="token string">"./data/"</span><span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>    os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span><span class="token comment">#下载ImageNet的class_index</span><span class="token comment">#是在Keras准备的。</span><span class="token comment"># https://github.com/fchollet/deep-learning-models/blob/master/imagenet_utils.py</span>url <span class="token operator">=</span> <span class="token string">"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json"</span>save_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">"imagenet_class_index.json"</span><span class="token punctuation">)</span><span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlretrieve<span class="token punctuation">(</span>url<span class="token punctuation">,</span> save_path<span class="token punctuation">)</span><span class="token comment">#1.3下载并解压缩你要用到的蚂蚁和蜜蜂的图像数据</span><span class="token comment"># 是在PyTorch指南课程中准备的。</span><span class="token comment"># https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html</span>url <span class="token operator">=</span> <span class="token string">"https://download.pytorch.org/tutorial/hymenoptera_data.zip"</span>save_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">"hymenoptera_data.zip"</span><span class="token punctuation">)</span><span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlretrieve<span class="token punctuation">(</span>url<span class="token punctuation">,</span> save_path<span class="token punctuation">)</span>    <span class="token comment"># 读取ZIP文件</span>    <span class="token builtin">zip</span> <span class="token operator">=</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span>    <span class="token builtin">zip</span><span class="token punctuation">.</span>extractall<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span>  <span class="token comment"># 解压缩ZIP</span>    <span class="token builtin">zip</span><span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 盗取ZIP文件</span>    <span class="token comment">#删除ZIP文件</span>    os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span>【※（实施完）】手动下载金毛寻回犬的图像https<span class="token punctuation">:</span><span class="token operator">//</span>pixabay<span class="token punctuation">.</span>com<span class="token operator">/</span>ja<span class="token operator">/</span>photos<span class="token operator">/</span>goldenretriever<span class="token operator">-</span><span class="token operator">%</span>E7<span class="token operator">%</span>8A<span class="token operator">%</span>AC<span class="token operator">-</span><span class="token number">3724972</span><span class="token operator">/</span>640x426尺寸的图像（图片版权信息<span class="token punctuation">:</span>CCO Creative Commons，免费商业使用，无需标注归属）将其直接放在文件夹“data”的下方。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p>导入软件包</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 导入软件包</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> json<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token operator">%</span>matplotlib inline<span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> models<span class="token punctuation">,</span> transforms<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>VGG-16已完成训练模型的载入</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#VGG-16已完成训练模型的载入</span><span class="token comment"># 第一次执行时，由于需要从网络下载学习好的参数数据，因此执行时间会稍微长一些</span><span class="token comment">#生成VGG-16模型的实例</span>use_pretrained <span class="token operator">=</span> <span class="token boolean">True</span>  <span class="token comment"># 使用已经训练好的参数</span>net <span class="token operator">=</span> models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span>use_pretrained<span class="token punctuation">)</span>net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 设置为推测模式</span><span class="token comment">#  输出模型的网络结构</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>实现一个对输入图片进行预处理的类BaseTransform()<br>注意：这里的__call__()作用是，如果不指定函数名而直接调用实例的变量名，<strong>call</strong>()函数内的代码直接会被执行。这里等于说就是直接返回一个被预处理过后的一个图片。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 对输入图片进行预处理的类</span><span class="token keyword">class</span> <span class="token class-name">BaseTransform</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    调整图片的尺寸，并对颜色进行规范化。    Attributes    ----------    resize : int       指定调整尺寸后图片的大小    mean : (R, G, B)       各个颜色通道的平均值    std : (R, G, B)       各个颜色通道的标准偏差    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> resize<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> std<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>base_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>            transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span>resize<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment">#将较短边的长度作为resize的大小</span>            transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span>resize<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment">#从图片中央截取resize × resize大小的区域</span>            transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment">#转换为Torch张量</span>            transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token punctuation">,</span> std<span class="token punctuation">)</span>  <span class="token comment">#颜色信息的正规化</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>base_transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>plt.show()一下预处理的效果，可省略.</p><p>注意：由于tentor即张量为( 颜色、高度、宽度 )，转换成np后需要转换为 ( 高度、宽度、颜色 )img_transformed = img_transformed.numpy().transpose((1, 2, 0))，如何限制范围为0~1，img_transformed = np.clip(img_transformed, 0, 1)</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#确认图像预处理的结果</span><span class="token comment"># 1. 读取图片</span>image_file_path <span class="token operator">=</span> <span class="token string">'./xxxxxxxxxx/xxx.jpg'</span>img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>image_file_path<span class="token punctuation">)</span>  <span class="token comment"># [高度][宽度][颜色RGB]</span><span class="token comment"># 2.  显示处理前的图片示</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 3. 同时显示预处理前后的图片</span>resize <span class="token operator">=</span> <span class="token number">224</span>mean <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">)</span>std <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span>transform <span class="token operator">=</span> BaseTransform<span class="token punctuation">(</span>resize<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> std<span class="token punctuation">)</span>img_transformed <span class="token operator">=</span> transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>  <span class="token comment"># torch.Size([3, 224, 224])</span><span class="token comment"># 将 ( 颜色、高度、宽度 ) 转换为 ( 高度、宽度、颜色 )，并将取值范围限制在0~1</span>img_transformed <span class="token operator">=</span> img_transformed<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>img_transformed <span class="token operator">=</span> np<span class="token punctuation">.</span>clip<span class="token punctuation">(</span>img_transformed<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img_transformed<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>实现一个处理输出后结果进行预测的类ILSVRCPredictor()，即实现将VGG16模型1000维的输出结果转换为分类标签的ILSVRCPredictor类。</p><p>从VGG-16模型输出的数值被保存到大小为torch.Size([1,1000])的PyTorch张量中，这里需要将其转换为NumPy变量。因此调用.debatch(),将输出结果从网路中分离出来；然后，对被debatch的张量进行.numpy()调用，将其转换为numpy变量，并用np.argmax()获取最大值的索引。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">ILSVRC_class_index <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./data/imagenet_class_index.json'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 根据输出结果对标签进行预测的后处理类</span><span class="token keyword">class</span> <span class="token class-name">ILSVRCPredictor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    根据ILSVRC数据，从模型的输出结果计算出分类标签    Attributes    ----------    class_index : dictionary           将类的index与标签名关联起来的字典型变量    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> class_index<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>class_index <span class="token operator">=</span> class_index    <span class="token keyword">def</span> <span class="token function">predict_max</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> out<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        获得概率最大的ILSVRC分类标签名        Parameters        ----------        out : torch.Size([1, 1000])            从Net中输出结果        Returns        -------        predicted_label_name : str            预测概率最高的分类标签的名称        """</span>        maxid <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>out<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment">#str()将数字-&gt;字符，class_index是字典，所以key是字符，故str(),再然后values是一个列表，列表第二个元素是#所分类别的名字,故[1]</span>        predicted_label_name <span class="token operator">=</span> self<span class="token punctuation">.</span>class_index<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>maxid<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> predicted_label_name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>调用已完成学习的VGG开始预测手头的图片啦</p><p>整理一下思路，输入的图片经过BaseTransform()预处理转换后，被作为VGG-16模型的输入数据输入。模型输出的1000维数据又经过ISVRCPredicor的处理，被转换为预测概率最高的分类标签名，并作为最终的输出结果返回。</p><p>注意，在将图片输入PyTorch网络中，需一小批次的形式传递，故使用.unsqueeze_(0),（英语单词非压缩，即扩展）0代表是第一维度，作用就是扩展一个维度，在整体大小不变的情况下，且增大的维度是第一维度（确实就batch_size=1）。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 载入ILSVRC的标签信息，并生成字典型变量</span>ILSVRC_class_index <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./data/imagenet_class_index.json'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 生成ILSVRCPredictor的实例</span>predictor <span class="token operator">=</span> ILSVRCPredictor<span class="token punctuation">(</span>ILSVRC_class_index<span class="token punctuation">)</span><span class="token comment"># 读取输入的图像</span>image_file_path <span class="token operator">=</span> <span class="token string">'./xxxx/xxxx.jpg'</span>img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>image_file_path<span class="token punctuation">)</span>  <span class="token comment"># [ 高度 ][ 宽度 ][ 颜色RGB]</span><span class="token comment"># 完成预处理后，添加批次尺寸的维度</span>transform <span class="token operator">=</span> BaseTransform<span class="token punctuation">(</span>resize<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> std<span class="token punctuation">)</span>  <span class="token comment">#创建预处理类</span>img_transformed <span class="token operator">=</span> transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>  <span class="token comment"># torch.Size([3, 224, 224])</span>inputs <span class="token operator">=</span> img_transformed<span class="token punctuation">.</span>unsqueeze_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># torch.Size([1, 3, 224, 224])</span><span class="token comment"># 输入数据到模型中，并将模型的输出转换为标签</span>out <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>  <span class="token comment"># torch.Size([1, 1000])</span>result <span class="token operator">=</span> predictor<span class="token punctuation">.</span>predict_max<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token comment"># 输出预测结果</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"输入图像的预测结果："</span><span class="token punctuation">,</span> result<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> DL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习入门笔记</title>
      <link href="/2023/10/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"/>
      <url>/2023/10/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>activation function :将输入信号的总和转换为输出信号，作用就是决定如何激活输入信号的总和。</p><h3 id="sigmoid-func"><a href="#sigmoid-func" class="headerlink" title="sigmoid func"></a>sigmoid func</h3><p>h(x) = 1 / 1 + exp(-x)</p><h3 id="阶跃函数"><a href="#阶跃函数" class="headerlink" title="阶跃函数"></a>阶跃函数</h3><p>相当于感知机  </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">step_fun</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">if</span> X <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">1</span>  <span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token comment">#np的类型</span><span class="token keyword">def</span> <span class="token function">step_fun</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    y <span class="token operator">=</span> x <span class="token operator">&gt;</span> <span class="token number">0</span>  <span class="token keyword">return</span> y<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="ReLU函数"><a href="#ReLU函数" class="headerlink" title="ReLU函数"></a>ReLU函数</h3><p>Rectified Linear Unit</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">relu</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">return</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="nn重要概念"><a href="#nn重要概念" class="headerlink" title="nn重要概念"></a>nn重要概念</h2><p>神经网络内积：<br><img src="/2023/10/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/20181219152354924.png"><br>![](屏幕截图 2023-10-14 142846.png)<br>输出层： softmax（）：yk = exp (ak) / exp (a1+a2+…+an)</p>]]></content>
      
      
      <categories>
          
          <category> DL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二叉树遍历(算法)</title>
      <link href="/2023/04/13/%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86-%E7%AE%97%E6%B3%95/"/>
      <url>/2023/04/13/%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86-%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="二叉树遍历"><a href="#二叉树遍历" class="headerlink" title="二叉树遍历"></a>二叉树遍历</h1><p><a href="https://www.acwing.com/problem/content/description/3387/">原题</a><br>思路：树的遍历<br>题意：已知二叉树的前序遍历(带有空节点位置)求中序遍历<br>一边“建树”，一边输出</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;using namespace std;void build(){    char ch = getchar();    if(ch == '#')        return ;    build();    cout &lt;&lt; ch &lt;&lt; ' ';    build();}int main(){    build();    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
          <category> 二叉树 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 二叉树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动手学深度学习（1）</title>
      <link href="/2023/04/12/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89/"/>
      <url>/2023/04/12/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h1><h2 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h2><p>在PyTorch中，torch.Tensor是存储和变换数据的主要工具。Tensor和NumPy的多维数组非常类似。然而，Tensor提供GPU计算和自动求梯度等更多功能，这些使Tensor更加适合深度学习。</p><p>“tensor”这个单词一般可译作“张量”，张量可以看作是一个多维数组。标量可以看作是0维张量，向量可以看作1维张量，矩阵可以看作是二维张量。</p><h3 id="创建Tensor"><a href="#创建Tensor" class="headerlink" title="创建Tensor"></a>创建Tensor</h3><p>首先导入pytorch</p><pre class="line-numbers language-none"><code class="language-none">import torch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后创建一个5x3的未初始化的Tensor</p><pre class="line-numbers language-none"><code class="language-none">x = torch.empty(5,3)print(x)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>创建一个5x3的随机初始化的Tensor</p><pre class="line-numbers language-none"><code class="language-none">x = torch.rand(5,3)print(x)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>创建一个5x3的long型全0的Tensor</p><pre class="line-numbers language-none"><code class="language-none">x = torch.zeros(5,3,dtype=torch.long)print(x)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>输出</p><pre class="line-numbers language-none"><code class="language-none">tensor([[0, 0, 0],        [0, 0, 0],        [0, 0, 0],        [0, 0, 0],        [0, 0, 0]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以根据数据创建</p><pre class="line-numbers language-none"><code class="language-none">x = torch.tensor([5.5,3])print(x)# tensor([5.5000, 3.0000])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>还可以通过现有的Tensor来创建，此方法会默认重用输入Tensor的一些属性，例如数据类型，除非自定义数据类型。</p><pre class="line-numbers language-none"><code class="language-none">x = x.new_ones(5, 3, dtype=torch.float64)  # 返回的tensor默认具有相同的torch.dtype和torch.deviceprint(x)x = torch.randn_like(x, dtype=torch.float) # 指定新的数据类型print(x) <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出</p><pre class="line-numbers language-none"><code class="language-none">tensor([[1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.]], dtype=torch.float64)tensor([[ 0.6035,  0.8110, -0.0451],        [ 0.8797,  1.0482, -0.0445],        [-0.7229,  2.8663, -0.5655],        [ 0.1604, -0.0254,  1.0739],        [ 2.2628, -0.9175, -0.2251]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过shape或size()来获取Tensor的形状</p><pre class="line-numbers language-none"><code class="language-none">print(x.size())print(x.shape)#均为torch.Size([5,3])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>注意：返回的torch.Size其实就是一个tuple, 支持所有tuple的操作。<br><img src="/2023/04/12/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89/image1.jpg"></p><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><h4 id="算术操作"><a href="#算术操作" class="headerlink" title="算术操作"></a>算术操作</h4><p>加法形式1</p><pre class="line-numbers language-none"><code class="language-none">y = torch.rand(5, 3)print(x + y)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>加法形式2</p><pre class="line-numbers language-none"><code class="language-none">print(torch.add(x, y))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>还可以指定输出</p><pre class="line-numbers language-none"><code class="language-none">result = torch.empty(5, 3)torch.add(x, y, out=result)print(result)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>加法形式3</p><pre class="line-numbers language-none"><code class="language-none"># adds x to yy.add_(x)print(y)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>注：PyTorch操作inplace版本都有后缀_, 例如x.copy_(y), x.t_()</p><h4 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h4><p>我们还可以使用类似NumPy的索引操作来访问Tensor的一部分，需要注意的是：索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。</p><pre class="line-numbers language-none"><code class="language-none">y = x[0, :] #第一行的，从头到尾y += 1print(y)print(x[0, :]) # 源tensor也被改了<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2023/04/12/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89/image2.jpg"></p><h4 id="改变形状"><a href="#改变形状" class="headerlink" title="改变形状"></a>改变形状</h4><p>用view()来改变Tensor的形状</p><pre class="line-numbers language-none"><code class="language-none">y = x.view(15)z = x.view(-1, 5)  # -1所指的维度可以根据其他维度的值推出来print(x.size(), y.size(), z.size())<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>输出</p><pre class="line-numbers language-none"><code class="language-none">torch.Size([5, 3]) torch.Size([15]) torch.Size([3, 5])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意view()返回的新Tensor与源Tensor虽然可能有不同的size，但是是共享data的，也即更改其中的一个，另外一个也会跟着改变。(顾名思义，view仅仅是改变了对这个张量的观察角度，内部数据并未改变)</p><pre class="line-numbers language-none"><code class="language-none">x += 1print(x)print(y) # 也加了1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>输出</p><pre class="line-numbers language-none"><code class="language-none">tensor([[1.6035, 1.8110, 0.9549],        [1.8797, 2.0482, 0.9555],        [0.2771, 3.8663, 0.4345],        [1.1604, 0.9746, 2.0739],        [3.2628, 0.0825, 0.7749]])tensor([1.6035, 1.8110, 0.9549, 1.8797, 2.0482, 0.9555, 0.2771, 3.8663, 0.4345,        1.1604, 0.9746, 2.0739, 3.2628, 0.0825, 0.7749])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>所以如果我们想返回一个真正新的副本（即不共享data内存）该怎么办呢？Pytorch还提供了一个reshape()可以改变形状，但是此函数并不能保证返回的是其拷贝，所以不推荐使用。推荐先用clone创造一个副本然后再使用view。<a href="https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch">参考此处</a></p><pre class="line-numbers language-none"><code class="language-none">x_cp = x.clone().view(15)x -= 1print(x)print(x_cp)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>输出</p><pre class="line-numbers language-none"><code class="language-none">tensor([[ 0.6035,  0.8110, -0.0451],        [ 0.8797,  1.0482, -0.0445],        [-0.7229,  2.8663, -0.5655],        [ 0.1604, -0.0254,  1.0739],        [ 2.2628, -0.9175, -0.2251]])tensor([1.6035, 1.8110, 0.9549, 1.8797, 2.0482, 0.9555, 0.2771, 3.8663, 0.4345,        1.1604, 0.9746, 2.0739, 3.2628, 0.0825, 0.7749])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用clone还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源Tensor。<br>另外一个常用的函数就是item(), 它可以将一个标量Tensor转换成一个Python number：</p><pre class="line-numbers language-none"><code class="language-none">x = torch.randn(1)print(x)print(x.item())<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>输出</p><pre class="line-numbers language-none"><code class="language-none">tensor([2.3466])2.3466382026672363<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h4><p><img src="/2023/04/12/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89/image3.jpg"><br>PyTorch中的Tensor支持超过一百种操作，包括转置、索引、切片、数学运算、线性代数、随机数等等，可参考<a href="https://pytorch.org/docs/stable/tensors.html">官方文档</a></p><h4 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h4><p>(之前都是相同形状运算)当对两个形状不同的Tensor按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个Tensor形状相同后再按元素运算。</p><pre class="line-numbers language-none"><code class="language-none">x = torch.arange(1, 3).view(1, 2)print(x)y = torch.arange(1, 4).view(3, 1)print(y)print(x + y)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出</p><pre class="line-numbers language-none"><code class="language-none">tensor([[1, 2]])tensor([[1],        [2],        [3]])tensor([[2, 3],        [3, 4],        [4, 5]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由于x和y分别是1行2列和3行1列的矩阵，如果要计算x + y，那么x中第一行的2个元素被广播（复制）到了第二行和第三行，而y中第一列的3个元素被广播（复制）到了第二列。如此，就可以对2个3行2列的矩阵按元素相加。</p><h3 id="运算的内存开销"><a href="#运算的内存开销" class="headerlink" title="运算的内存开销"></a>运算的内存开销</h3><p>索引操作是不会开辟新内存的，而像y = x + y这样的运算是会新开内存的，然后将y指向新内存。为了演示这一点，我们可以使用Python自带的id函数：如果两个实例的ID一致，那么它们所对应的内存地址相同；反之则不同。</p><pre class="line-numbers language-none"><code class="language-none">x = torch.tensor([1, 2])y = torch.tensor([3, 4])id_before = id(y)y = y + xprint(id(y) == id_before) # False <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果想指定结果到原来的y的内存，我们可以使用前面介绍的索引来进行替换操作。在下面的例子中，我们把x + y的结果通过[:]写进y对应的内存中。</p><pre class="line-numbers language-none"><code class="language-none">x = torch.tensor([1, 2])y = torch.tensor([3, 4])id_before = id(y)y[:] = y + xprint(id(y) == id_before) # True<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们还可以使用运算符全名函数中的out参数或者自加运算符+=(也即add_())达到上述效果，例如torch.add(x, y, out=y)和y += x(y.add_(x))。</p><pre class="line-numbers language-none"><code class="language-none">x = torch.tensor([1, 2])y = torch.tensor([3, 4])id_before = id(y)torch.add(x, y, out=y) # y += x, y.add_(x)print(id(y) == id_before) # True<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注：虽然view返回的Tensor与源Tensor是共享data的，但是依然是一个新的Tensor（因为Tensor除了包含data外还有一些其他属性），二者id（内存地址）并不一致。</p><h3 id="Tensor和Numpy相互转换"><a href="#Tensor和Numpy相互转换" class="headerlink" title="Tensor和Numpy相互转换"></a>Tensor和Numpy相互转换</h3><p>我们很容易用numpy()和from_numpy()将Tensor和NumPy中的数组相互转换。但是需要注意的一点是： 这两个函数所产生的的Tensor和NumPy中的数组共享相同的内存（所以他们之间的转换很快），改变其中一个时另一个也会改变！！！</p><blockquote><p>还有一个常用的将NumPy中的array转换成Tensor的方法就是torch.tensor(), 需要注意的是，此方法总是会进行数据拷贝（就会消耗更多的时间和空间），所以返回的Tensor和原来的数据不再共享内存。</p></blockquote><h4 id="Tensor转Numpy"><a href="#Tensor转Numpy" class="headerlink" title="Tensor转Numpy"></a>Tensor转Numpy</h4><p>使用numpy()将Tensor转换成NumPy数组:</p><pre class="line-numbers language-none"><code class="language-none">a = torch.ones(5)b = a.numpy()print(a, b)a += 1print(a, b)b += 1print(a, b)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出：</p><pre class="line-numbers language-none"><code class="language-none">tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="NumPy数组转Tensor"><a href="#NumPy数组转Tensor" class="headerlink" title="NumPy数组转Tensor"></a>NumPy数组转Tensor</h4><p>使用from_numpy()将NumPy数组转换成Tensor:</p><pre class="line-numbers language-none"><code class="language-none">import numpy as npa = np.ones(5)b = torch.from_numpy(a)print(a, b)a += 1print(a, b)b += 1print(a, b)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出:</p><pre class="line-numbers language-none"><code class="language-none">[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)[2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)[3. 3. 3. 3. 3.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>所有在CPU上的Tensor（除了CharTensor）都支持与NumPy数组相互转换。</p><p>此外上面提到还有一个常用的方法就是直接用torch.tensor()将NumPy数组转换成Tensor，需要注意的是该方法总是会进行数据拷贝，返回的Tensor和原来的数据不再共享内存。</p><pre class="line-numbers language-none"><code class="language-none">c = torch.tensor(a)a += 1print(a, c)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>输出</p><pre class="line-numbers language-none"><code class="language-none">[4. 4. 4. 4. 4.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Tensor-on-GPU"><a href="#Tensor-on-GPU" class="headerlink" title="Tensor on GPU"></a>Tensor on GPU</h3><p>方法to()可以将CPU和GPU之间相互移动</p><pre class="line-numbers language-none"><code class="language-none"># 以下代码只有在PyTorch GPU版本上才会执行if torch.cuda.is_available():    device = torch.device("cuda")          # GPU    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor    x = x.to(device)                       # 等价于 .to("cuda")    z = x + y    print(z)    print(z.to("cpu", torch.double))       # to()还可以同时更改数据类型<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 《动手学深度学习》自学笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编译原理3.29</title>
      <link href="/2023/03/29/%E7%BC%96%E8%AF%913-29/"/>
      <url>/2023/03/29/%E7%BC%96%E8%AF%913-29/</url>
      
        <content type="html"><![CDATA[<h1 id="第一章-引论"><a href="#第一章-引论" class="headerlink" title="第一章 引论"></a>第一章 引论</h1><h2 id="1-1程序的翻译"><a href="#1-1程序的翻译" class="headerlink" title="1.1程序的翻译"></a>1.1程序的翻译</h2><p>翻译程序： 源语言-&gt;与之等价的目标语言<br>两种方式：1、编译 2、解释  </p><h3 id="编译方式"><a href="#编译方式" class="headerlink" title="编译方式"></a>编译方式</h3><p>编译方式是一种分阶段进行的方式<br>翻译阶段：高级语言或汇编语言程序-&gt;汇编语言或机器语言的目标程序<br>运行阶段：输入数据–目标程序&amp;系统子程序–&gt;运行结果<br>特点：  </p><ul><li>源程序的执行需要分阶段  <ul><li>如果目标程序是机器语言程序，两大阶段：编译阶段和运行阶段。</li><li>如果目标程序是汇编语言程序，三大阶段：编译阶段、汇编阶段和运行阶段。</li></ul></li><li>生成了目标代码，且可以多次执行。</li></ul><p>说明：  </p><ul><li>生成的目标程序<u>不一定</u>是机器语言的程序，也有可能是汇编语言程序；</li><li>编译程序与<u>具体的机器和语言有关</u>，即任何一个具体的编译程序都是某一特定类型的计算机系统中关于某一特定语言的编译程序；</li><li>对编译程序而言，<u>源程序</u>是输入数据，<u>目标程序</u>是输出结果</li></ul><h3 id="解释方式"><a href="#解释方式" class="headerlink" title="解释方式"></a>解释方式</h3><p>解释程序将按源程序中<del>语句的动态顺序</del>，逐句地进行分析解释，并<del>立即</del>予以<del>执行</del>。<br>特点：</p><ul><li>不生成目标代码，直接执行源程序本身。与前者方式的<del>根本区别</del>。</li><li>都需要进行词法、语法、语义分析</li><li>更灵活，交互方便，节省空间</li><li>效率低（时间开销、空间开销）</li></ul><p><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images.jpg"></p><h2 id="1-2编译程序的工作过程"><a href="#1-2编译程序的工作过程" class="headerlink" title="1.2编译程序的工作过程"></a>1.2编译程序的工作过程</h2><ul><li>词法分析</li><li>语法分析</li><li>语义分析和中间代码生成</li><li>中间代码优化</li><li>目标代码生成</li></ul><h3 id="词法分析"><a href="#词法分析" class="headerlink" title="词法分析"></a>词法分析</h3><p>依据语言<font color="red">词法规则</font>，分析由字符组成的源程序，把它识别为一个一个具有独立意义的<font color="red">最小语法单位</font>，即“<font color="red">单词</font>”，并识别出与其相关的属性（如是标识符还是界限符，or数..）再转换成<font color="red">长度上统一</font>的标准形式（这个形式既刻画单词本身，又刻画了它具有的属性，称为<font color="red">属性字</font>），以供其他部分使用。  </p><ul><li>扫描源程序的字符串，识别单词（关键字、标识符、常量、运算符、界限符）</li></ul><p>eg:<br><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images1.jpg"></p><p>属性字： &lt;类别号class，自身值value&gt;</p><h3 id="语法分析"><a href="#语法分析" class="headerlink" title="语法分析"></a>语法分析</h3><p>依据<font color="red">语法规则</font>，逐一分析词法分析时得到的单词，把单词串分解成各类语法单位，即确定<font color="red">它们是怎样组成和语句，以及说明语句又是怎样组成程序的</font>。分析时如发现有不合语法规则的地方，便将出错的位置及出错性质打印报告程序员。如无语法错误，则用另一种中间形式给出正确的语法结构，供下一阶段分析使用。</p><h3 id="语义分析"><a href="#语义分析" class="headerlink" title="语义分析"></a>语义分析</h3><p>依据语言的语义规则对语法分析得到的语法结构进行静态语义检查（确定类型、类型和运算合法性检查、识别含义与相 应的语义处理及其它一些静态语义检查），并用另一种内部形式表示出来，或者直接用目标语言表示出来。<br>凡在编译时可以确定的内容称为“静态”的；凡必须推迟 到程序运行时才能确定的内容称为“动态”的</p><h3 id="代码优化"><a href="#代码优化" class="headerlink" title="代码优化"></a>代码优化</h3><p>依据程序的等价变换规则，尽量压缩目标程序运行所需的 时间和所占的存储空间，以提高目标程序的质量。<br>优化的是中间代码/目标代码的质量，而非编译程序的质量</p><h3 id="代码生成"><a href="#代码生成" class="headerlink" title="代码生成"></a>代码生成</h3><p>如果语义分析时把源程序表示成中间形式而不是表示成目标指令，则由本部分完成从中间形式到目标指令的转换。如果语义分析时，已直接生成目标指令，则无需另外再做代码生成工作。<br>目标指令可能是绝对指令代码，或可重新定位的指令代码 或汇编指令代码。该阶段的工作有赖于硬件系统结构和机器指令含义。</p><h3 id="表格管理"><a href="#表格管理" class="headerlink" title="表格管理"></a>表格管理</h3><p>登记源程序中出现的每个名字以及名字的各种属性。有些名字的属性需要在各个阶段才能填入。<br><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images2.jpg"></p><h3 id="出错处理"><a href="#出错处理" class="headerlink" title="出错处理"></a>出错处理</h3><p>源程序中的错误有语法错误和语义错误两种。</p><p>语法错误：源程序中不符合语法（或词法）规则的错误，它们可在词法分析或语法分析时检测出来。</p><p>语义错误：源程序中不符合语义规则的错误，一般在语义分析时检测出来，有的语义错误要在运行时才能检测出来。通常包括：说明错误、作用域错误、类型不一致等等。</p><h2 id="1-3编译程序的结构"><a href="#1-3编译程序的结构" class="headerlink" title="1.3编译程序的结构"></a>1.3编译程序的结构</h2><p><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images3.jpg"></p><h2 id="1-4编译程序的组织形式"><a href="#1-4编译程序的组织形式" class="headerlink" title="1.4编译程序的组织形式"></a>1.4编译程序的组织形式</h2><h3 id="遍（趟，趟程）"><a href="#遍（趟，趟程）" class="headerlink" title="遍（趟，趟程）"></a>遍（趟，趟程）</h3><p>所谓一趟或一遍是指一个编译程序在编译时刻把源程序或源 程序的等价物（中间程序）从头到尾扫描一遍并转换成另一紧邻的 等价物的全过程。</p><p>根据编译程序在完成翻译任务的过程中需要对源程序或其中间等价物扫描的遍数，可以把编译程序分为单遍扫描的编译程序 （只需扫描一遍）和多遍扫描的编译程序（需扫描多遍）。<br><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images4.jpg"></p><p>多遍的特点：<br>优点：</p><ul><li>节省内存空间</li><li>提高目标程序质量</li><li>缩短Compiler的开发周期</li></ul><p>缺点：  </p><ul><li>重复性工作</li><li>延长了编译时间，降低了编译效率</li></ul><p>并非单遍/多遍一定就好，视情况而定。<br>选择编译的“遍”数的原则：  </p><ul><li>语言的大小、结构</li><li>机器的规模</li><li>设计的目的（如：编译速度、目标程序的运行速度）</li><li>设计人员素质多少</li></ul><h3 id="编译的前端和后端"><a href="#编译的前端和后端" class="headerlink" title="编译的前端和后端"></a>编译的前端和后端</h3><ul><li>前端主要由与源语言有关但与目标机器无关的那些部分组成, 如词法分析、语法分析、语义分析与中间代码生成及部分代码优 化工作。  </li><li>后端主要包括编译中与目标机器有关的那些部分，如与目标 机有关的代码优化和目标代码生成等。后端不依赖于源语言而仅 依赖于中间语言。<br><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images5.jpg"></li></ul><p><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images6.jpg"></p><h2 id="1-5编译程序的构造"><a href="#1-5编译程序的构造" class="headerlink" title="1.5编译程序的构造"></a>1.5编译程序的构造</h2><h3 id="高级语言的自编译性高级语言的自编译性"><a href="#高级语言的自编译性高级语言的自编译性" class="headerlink" title="高级语言的自编译性高级语言的自编译性"></a>高级语言的自编译性高级语言的自编译性</h3><p>构造编译程序可以用机器言语、汇编语言和高级语言<br>高级语言的自编译性：一个语言可以用来编写自己的编 译程序。<br><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images7.jpg"></p><p><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images8.jpg"></p><h3 id="编译的自展技术"><a href="#编译的自展技术" class="headerlink" title="编译的自展技术"></a>编译的自展技术</h3><p>即通过一系列自展途径而形成编译程序的过程。<br>先对语言的核心部分构造一个小小编译程序（可用低级语 言实现），再以它为工具构造一个能够编译更多语言成分的较大编译程序。如此扩展下去，越滚越大，最后形成所期望的整个编译程序。<br><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images9.jpg"></p><h3 id="编译的移植"><a href="#编译的移植" class="headerlink" title="编译的移植"></a>编译的移植</h3><p>即将一个机器（宿主机）上的一个具有自编译性的高级语 言编译程序移植到另一个机器（目标机）上。<br>利用A机器上的高级语言L编写能在B机器上运行的高级语言L的编译程序。<br><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images10.jpg"></p><p><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images11.jpg"></p><h3 id="编译程序的自动化"><a href="#编译程序的自动化" class="headerlink" title="编译程序的自动化"></a>编译程序的自动化</h3><p><img src="/2023/03/29/%E7%BC%96%E8%AF%913-29/images12.jpg"></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>什么是编译程序</li><li>编译方式的特点</li><li>解释方式的特点</li><li>编译方式与解释方式的根本区别</li><li>编译程序的工作过程</li><li>编译程序的结构</li><li>遍与编译程序的组织形式</li><li>编译程序的构造方法</li></ul>]]></content>
      
      
      <categories>
          
          <category> CP notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CP notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/03/28/hello-world/"/>
      <url>/2023/03/28/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
